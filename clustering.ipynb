{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6257/1971294669.py:11: DtypeWarning: Columns (1,1687,1688) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_dossier_complet_brut = pd.read_csv(file)\n",
      "/tmp/ipykernel_6257/1971294669.py:16: DtypeWarning: Columns (4,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_meta_dossier_complet_brut = pd.read_csv(file)\n",
      "/tmp/ipykernel_6257/1971294669.py:21: DtypeWarning: Columns (1,2,3,4,14,15,16,18,22,24,27,30,31,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_mobpro_brut = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions de la matrice : (34881, 34078)\n",
      "Dimensions de la matrice (TRANS = 4 ou 5) : (34817, 33012)\n",
      "Dimensions de la matrice (TRANS = 6) : (17600, 10140)\n",
      "Dimensions de la matrice (TRANS = 1, 2 ou 3) : (30250, 29908)\n"
     ]
    }
   ],
   "source": [
    "import s3fs\n",
    "import pandas as pd\n",
    "# Information d'accès au cloud MinIO (Bucket de William)\n",
    "fs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\n",
    "MY_BUCKET = \"williamolivier\"\n",
    "# Vérification du contenu\n",
    "fs.ls(f\"{MY_BUCKET}/diffusion\")\n",
    "# Récupération des tableaux\n",
    "FILE_PATH_S3_DCB = f\"{MY_BUCKET}/diffusion/df_dossier_complet_brut.csv\"\n",
    "with fs.open(FILE_PATH_S3_DCB, \"rb\") as file:\n",
    "    df_dossier_complet_brut = pd.read_csv(file)\n",
    "\n",
    "# Récupération des tableaux\n",
    "FILE_PATH_S3_MDCB = f\"{MY_BUCKET}/diffusion/df_meta_dossier_complet_brut.csv\"\n",
    "with fs.open(FILE_PATH_S3_MDCB, \"rb\") as file:\n",
    "    df_meta_dossier_complet_brut = pd.read_csv(file)\n",
    "\n",
    "# Récupération des tableaux\n",
    "FILE_PATH_S3_MB = f\"{MY_BUCKET}/diffusion/df_mobpro_brut.csv\"\n",
    "with fs.open(FILE_PATH_S3_MB, \"rb\") as file:\n",
    "    df_mobpro_brut = pd.read_csv(file)\n",
    "\n",
    "# Récupération des tableaux\n",
    "FILE_PATH_S3_MMB = f\"{MY_BUCKET}/diffusion/df_meta_mobpro_brut.csv\"\n",
    "with fs.open(FILE_PATH_S3_MMB, \"rb\") as file:\n",
    "    df_meta_mobpro_brut = pd.read_csv(file)\n",
    "# Homogénéisation des codes insee (tous en chaîne de caractère)\n",
    "df_mobpro_brut[\"COMMUNE\"] = df_mobpro_brut[\"COMMUNE\"].astype(str).str.zfill(5)\n",
    "df_mobpro_brut[\"DCLT\"] = df_mobpro_brut[\"DCLT\"].astype(str).str.zfill(5)\n",
    "df_mobpro_brut[\"ARM\"] = df_mobpro_brut[\"ARM\"].astype(str).str.zfill(5)\n",
    "# Conversion des colonnes en numérique\n",
    "df_mobpro_brut['NPERR'] = pd.to_numeric(df_mobpro_brut['NPERR'], errors='coerce')\n",
    "df_mobpro_brut['INPSM'] = pd.to_numeric(df_mobpro_brut['INPSM'], errors='coerce')\n",
    "df_mobpro_brut['INPOM'] = pd.to_numeric(df_mobpro_brut['INPOM'], errors='coerce')\n",
    "df_mobpro_brut['INEEM'] = pd.to_numeric(df_mobpro_brut['INEEM'], errors='coerce')\n",
    "\n",
    "# Création des agrégations de base\n",
    "mobpro_villes = df_mobpro_brut.groupby('COMMUNE').agg({\n",
    "    'NPERR': 'sum',\n",
    "    'INPSM': 'sum',\n",
    "    'INPOM': 'sum',\n",
    "    'INEEM': 'sum'})\n",
    "\n",
    "# Créons d'abord un DataFrame temporaire pour chaque valeur d'ILT\n",
    "for i in range(1, 8):\n",
    "    # Grouper par COMMUNE et compter les occurrences où ILT == str(i)\n",
    "    temp_count = df_mobpro_brut[df_mobpro_brut['ILT'] == i].groupby('COMMUNE').size()\n",
    "    # Ajouter cette série au DataFrame principal\n",
    "    mobpro_villes[f'ILT_{i}'] = temp_count\n",
    "\n",
    "# Remplir les valeurs manquantes (NaN) par 0\n",
    "mobpro_villes = mobpro_villes.fillna(0)\n",
    "\n",
    "# Réinitialisation de l'index\n",
    "mobpro_villes = mobpro_villes.reset_index()\n",
    "\n",
    "# On vérifie qu'il y a autant de lignes avec un arrondissement indiqué et de lignes dont la ville de résidence est soit Paris, soit Marseille, soit Lyon (cohérence entre \"ARM\" et \"COMMUNE\")\n",
    "assert len(df_mobpro_brut[df_mobpro_brut['ARM']!=\"ZZZZZ\"])== len(df_mobpro_brut[\n",
    "    (df_mobpro_brut['COMMUNE'] == '75056') | \n",
    "    (df_mobpro_brut['COMMUNE'] == '13055') | \n",
    "    (df_mobpro_brut['COMMUNE'] == '69123')])\n",
    "\n",
    "# Liste des codes insee d'arrondissements\n",
    "arr_paris = [f\"751{str(i).zfill(2)}\" for i in range(1, 21)]\n",
    "arr_marseille = [f\"132{str(i).zfill(2)}\" for i in range(1, 17)]\n",
    "arr_lyon = [f\"6938{str(i).zfill(1)}\" for i in range(1, 10)]\n",
    "df_mobpro_brut.loc[\n",
    "    df_mobpro_brut['COMMUNE'].isin(['75056', '13055', '69123']), 'COMMUNE'\n",
    "] = df_mobpro_brut['ARM']\n",
    "\n",
    "# Création d'une table croisée dynamique pour compter les déplacements\n",
    "flux_tot = pd.crosstab(df_mobpro_brut['COMMUNE'], df_mobpro_brut['DCLT'])\n",
    "\n",
    "# Conversion en DataFrame pour plus de clarté\n",
    "flux_tot = pd.DataFrame(flux_tot)\n",
    "\n",
    "# En option, si on veut réinitialiser l'index pour avoir COMMUNE en colonne :\n",
    "# flux_tot = flux_tot.reset_index()\n",
    "\n",
    "# Pour voir les dimensions de la matrice\n",
    "print(\"Dimensions de la matrice :\", flux_tot.shape)\n",
    "\n",
    "\n",
    "# Filtrer les données pour chaque groupe de transport\n",
    "df_trans_45 = df_mobpro_brut[df_mobpro_brut['TRANS'].isin([4, 5])]\n",
    "df_trans_6 = df_mobpro_brut[df_mobpro_brut['TRANS'] == 6]\n",
    "df_trans_123 = df_mobpro_brut[df_mobpro_brut['TRANS'].isin([1, 2, 3])]\n",
    "\n",
    "# Créer les matrices des flux pour chaque groupe\n",
    "flux_rouge = pd.crosstab(df_trans_45['COMMUNE'], df_trans_45['DCLT'])\n",
    "flux_jaune = pd.crosstab(df_trans_6['COMMUNE'], df_trans_6['DCLT'])\n",
    "flux_vert = pd.crosstab(df_trans_123['COMMUNE'], df_trans_123['DCLT'])\n",
    "\n",
    "# Convertir en DataFrame pour plus de clarté\n",
    "flux_rouge = pd.DataFrame(flux_rouge)\n",
    "flux_jaune = pd.DataFrame(flux_jaune)\n",
    "flux_vert = pd.DataFrame(flux_vert)\n",
    "\n",
    "# Afficher les dimensions des matrices\n",
    "print(\"Dimensions de la matrice (TRANS = 4 ou 5) :\", flux_rouge.shape)\n",
    "print(\"Dimensions de la matrice (TRANS = 6) :\", flux_jaune.shape)\n",
    "print(\"Dimensions de la matrice (TRANS = 1, 2 ou 3) :\", flux_vert.shape)\n",
    "\n",
    "def flux(ville_a,ville_b):\n",
    "    flux = flux_tot.loc[ville_a, ville_b]\n",
    "    print(f\"Nombre de personnes se déplaçant de {ville_a} vers {ville_b} : {flux}\")\n",
    "\n",
    "## Prend en arg deux codes insee en chaîne de caractère et renvoie le nombre de commute entre ces deux villes\n",
    "\n",
    "# Top 10 des villes générant le plus de déplacements\n",
    "top_villes_depart = flux_tot.sum(axis=1).sort_values(ascending=False).head(10)\n",
    "top_villes_arrivee = flux_tot.sum(axis=0).sort_values(ascending=False).head(10)\n",
    "\n",
    "transport_dict = {\n",
    "    1: \"Pas de transport\",\n",
    "    2: \"Marche à pied (ou rollers, patinette)\",\n",
    "    3: \"Vélo (y compris à assistance électrique)\",\n",
    "    4: \"Deux-roues motorisé\",\n",
    "    5: \"Voiture, camion, fourgonnette\",\n",
    "    6: \"Transports en commun\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
