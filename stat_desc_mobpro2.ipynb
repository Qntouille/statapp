{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711424ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e788ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83825e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from script import df_mobpro_brut, arr_marseille, arr_paris, arr_lyon, contours_comm, transport_dict, contours_comm, flux, plot_flux_gradient, plot_flux_gradient_zoom, coord_villes\n",
    "from script import df_dossier_complet_brut, mairies, df_epci_contours, df_flux_jaune_destination_m,df_flux_rouge_destination_m,df_flux_vert_destination_m, df_flux_rouge_depart_m,df_flux_jaune_depart_m,df_flux_vert_depart_m\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import numpy as np\n",
    "import matplotlib.colors as colors\n",
    "import networkx as nx\n",
    "from scipy.sparse import coo_matrix\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import unary_union\n",
    "from shapely import wkt\n",
    "from haversine import haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5075cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "mairies[['lat', 'lon']] = mairies['Coordonnées'].str.split(',', expand=True).astype(float)\n",
    "mairies_unique = mairies.drop_duplicates(subset='Code INSEE')\n",
    "\n",
    "# Calculer le trajet interne\n",
    "def approx_internal_distance(geom):\n",
    "    bounds = geom.bounds  # (minx, miny, maxx, maxy)\n",
    "    point_min = (bounds[1], bounds[0])  # (lat_min, lon_min)\n",
    "    point_max = (bounds[3], bounds[2])  # (lat_max, lon_max)\n",
    "    return haversine(point_min, point_max)\n",
    "\n",
    "contours_comm['distance_intra'] = contours_comm['geometry'].apply(approx_internal_distance)/2 # On divise par 2 la diag pour les intra\n",
    "distance_intra_dict = contours_comm.set_index('INSEE_COM')['distance_intra'].to_dict() # Dictionnaire des distances intra\n",
    "\n",
    "# Calculer les trajets entre villes\n",
    "mairies_unique = mairies.drop_duplicates(subset='Code INSEE') # Garder une seule mairie pour chaque ville\n",
    "coords_mairies = mairies_unique.set_index('Code INSEE')[['lat', 'lon']].to_dict('index') \n",
    "\n",
    "# Fonction pour calculer la distance\n",
    "def calculer_distance(code_depart, code_arrivee):\n",
    "    if code_depart == code_arrivee:\n",
    "        # Trajet intra-communal\n",
    "        return distance_intra_dict.get(code_depart, 3.0)  # Fallback 3km si pas trouvé\n",
    "    else:\n",
    "        # Trajet intercommunal\n",
    "        coords_depart = coords_mairies.get(code_depart)\n",
    "        coords_arrivee = coords_mairies.get(code_arrivee)\n",
    "        \n",
    "        if coords_depart is None or coords_arrivee is None:\n",
    "            return None  # Impossible de calculer (missing coords)\n",
    "        \n",
    "        return haversine((coords_depart['lat'], coords_depart['lon']),\n",
    "                         (coords_arrivee['lat'], coords_arrivee['lon']))\n",
    "\n",
    "df_mobpro_brut['distance_km'] = df_mobpro_brut.apply(\n",
    "    lambda row: calculer_distance(row['COMMUNE'], row['DCLT']),\n",
    "    axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e87900",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mobpro_brut.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2563191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_mono_departement(liste_departements):\n",
    "    '''\n",
    "    On vérifie si les EPCI regroupent forcément des villes qui appartiennent au même département (réponse = non pas systématiquement)\n",
    "    '''\n",
    "    liste_departements = ast.literal_eval(liste_departements)\n",
    "    return len(set(liste_departements)) == 1\n",
    "    \n",
    "    \n",
    "# Appliquer la fonction à chaque ligne et créer une nouvelle colonne\n",
    "df_epci_contours['MONO_DEP'] = df_epci_contours['INSEE_DEP'].apply(est_mono_departement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6151664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"OBTENTION DE gdf_epci_metropole IGNORANT LES EPCI HORS FRANCE METROPOLITAINE\"\"\"\n",
    "\n",
    "def est_metropole(liste_departements):\n",
    "    \"\"\"\n",
    "    Exclut les DOM-TOM et la Corse, ne conserve que la métropole.\n",
    "    \"\"\"\n",
    "    if isinstance(liste_departements, str):\n",
    "        try:\n",
    "            liste_departements = ast.literal_eval(liste_departements)\n",
    "        except Exception:\n",
    "            return False  # La chaîne n'était pas une liste valide\n",
    "\n",
    "    # Filtrage : ignorer les départements trop longs\n",
    "    liste_departements = [str(dep).strip() for dep in liste_departements if len(str(dep).strip()) <= 3]\n",
    "\n",
    "    for dep in liste_departements:\n",
    "        # Exclure les codes contenant des lettres (ex: 2A ou 2B pour la Corse)\n",
    "        if any(c.isalpha() for c in dep):\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            if int(dep) >= 970:\n",
    "                return False\n",
    "        except ValueError:\n",
    "            return False  # On exclut si ce n'est pas un entier valide\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f9a190",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_epci_metropole = df_epci_contours[df_epci_contours['INSEE_DEP'].apply(est_metropole)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d9f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier le type des données dans la colonne geometry\n",
    "print(type(gdf_epci_metropole['geometry'].iloc[0]))\n",
    "\n",
    "# Si les données sont déjà des objets géométriques, ne pas les convertir\n",
    "# Sinon, convertir seulement si c'est une chaîne de caractères\n",
    "def convert_if_string(geom):\n",
    "    if isinstance(geom, str):\n",
    "        return wkt.loads(geom)\n",
    "    return geom\n",
    "\n",
    "gdf_epci_metropole['geometry'] = gdf_epci_metropole['geometry'].apply(convert_if_string)\n",
    "\n",
    "# Créer un GeoDataFrame\n",
    "gdf_epci_metropole = gpd.GeoDataFrame(gdf_epci_metropole, geometry='geometry')\n",
    "\n",
    "# Tracer les contours des EPCI\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "gdf_epci_metropole.plot(ax=ax, edgecolor='black', facecolor='none')\n",
    "plt.title('Contours des EPCI')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee416d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_epci_metropole.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecf2788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour convertir les chaînes de caractères en listes\n",
    "def convert_to_list(value):\n",
    "    if isinstance(value, str):\n",
    "        # Supprime les caractères indésirables et divise la chaîne\n",
    "        cleaned = value.replace('[', '').replace(']', '').replace(\"'\", '').replace('\"', '')\n",
    "        # Divise la chaîne en éléments individuels\n",
    "        items = [item.strip() for item in cleaned.split(',') if item.strip()]\n",
    "        return items\n",
    "    elif isinstance(value, list):\n",
    "        return value\n",
    "    return []\n",
    "\n",
    "# 1. Convertir les colonnes de codes INSEE en listes\n",
    "print(\"Conversion des codes INSEE en listes...\")\n",
    "gdf_epci_metropole['INSEE_COM_list'] = gdf_epci_metropole['INSEE_COM'].apply(convert_to_list)\n",
    "gdf_epci_metropole['INSEE_DEP_list'] = gdf_epci_metropole['INSEE_DEP'].apply(convert_to_list)\n",
    "\n",
    "# 2. Définir les tranches de distances\n",
    "distance_bins = [0, 10, 20, 30, 40, 50, float('inf')]\n",
    "distance_labels = ['<10km', '<20km', '<30km', '<40km', '<50km', '>50km']\n",
    "\n",
    "# 3. Définir les catégories de transport\n",
    "transport_categories = {\n",
    "    'vert': ['1', '2', '3'],\n",
    "    'jaune': ['6'],\n",
    "    'rouge': ['4', '5']\n",
    "}\n",
    "\n",
    "# Créer un dictionnaire pour stocker les résultats\n",
    "results = {}\n",
    "\n",
    "# Boucle sur chaque EPCI\n",
    "print(\"Calcul des statistiques par EPCI...\")\n",
    "for idx, epci_row in gdf_epci_metropole.iterrows():\n",
    "    epci_communes = set(epci_row['INSEE_COM_list'])\n",
    "    epci_code = epci_row['SIREN_EPCI']\n",
    "    \n",
    "    # Initialiser le dictionnaire pour cet EPCI\n",
    "    results[epci_code] = {}\n",
    "    \n",
    "    # Pour chaque catégorie de transport\n",
    "    for transport_name, transport_codes in transport_categories.items():\n",
    "        \n",
    "        # Filtrer les données de mobilité pour cette catégorie de transport\n",
    "        transport_data = df_mobpro_brut[df_mobpro_brut['TRANS'].isin(transport_codes)]\n",
    "        \n",
    "        # Identifier les flux entrants, sortants et internes\n",
    "        entrants = transport_data[\n",
    "            (~transport_data['DCLT'].isin(epci_communes)) & \n",
    "            (transport_data['COMMUNE'].isin(epci_communes))\n",
    "        ]\n",
    "        \n",
    "        sortants = transport_data[\n",
    "            (transport_data['DCLT'].isin(epci_communes)) & \n",
    "            (~transport_data['COMMUNE'].isin(epci_communes))\n",
    "        ]\n",
    "        \n",
    "        internes = transport_data[\n",
    "            (transport_data['DCLT'].isin(epci_communes)) & \n",
    "            (transport_data['COMMUNE'].isin(epci_communes))\n",
    "        ]\n",
    "        \n",
    "        # Calculer les statistiques par tranche de distance\n",
    "        for i, (lower, upper) in enumerate(zip(distance_bins[:-1], distance_bins[1:])):\n",
    "            label = distance_labels[i]\n",
    "            \n",
    "            # Flux entrants\n",
    "            entrants_bin = entrants[(entrants['distance_km'] > lower) & (entrants['distance_km'] <= upper)]\n",
    "            results[epci_code][f'nb_entrant_{label}_{transport_name}'] = entrants_bin['IPONDI'].sum()\n",
    "            results[epci_code][f'distance_entrant_{label}_{transport_name}'] = (entrants_bin['distance_km'] * entrants_bin['IPONDI']).sum() / entrants_bin['IPONDI'].sum() if entrants_bin['IPONDI'].sum() > 0 else 0\n",
    "            \n",
    "            # Flux sortants\n",
    "            sortants_bin = sortants[(sortants['distance_km'] > lower) & (sortants['distance_km'] <= upper)]\n",
    "            results[epci_code][f'nb_sortant_{label}_{transport_name}'] = sortants_bin['IPONDI'].sum()\n",
    "            results[epci_code][f'distance_sortant_{label}_{transport_name}'] = (sortants_bin['distance_km'] * sortants_bin['IPONDI']).sum() / sortants_bin['IPONDI'].sum() if sortants_bin['IPONDI'].sum() > 0 else 0\n",
    "        \n",
    "        # Flux internes (pas de segmentation par distance)\n",
    "        results[epci_code][f'nb_intra_{transport_name}'] = internes['IPONDI'].sum()\n",
    "        results[epci_code][f'distance_intra_{transport_name}'] = (internes['distance_km'] * internes['IPONDI']).sum() / internes['IPONDI'].sum() if internes['IPONDI'].sum() > 0 else 0\n",
    "\n",
    "# Convertir les résultats en DataFrame\n",
    "print(\"Conversion des résultats en DataFrame...\")\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "\n",
    "# Joindre les résultats au GeoDataFrame original\n",
    "print(\"Jointure des résultats au GeoDataFrame...\")\n",
    "gdf_epci_metropole_enrichi = gdf_epci_metropole.merge(results_df, left_on='SIREN_EPCI', right_index=True, how='left')\n",
    "\n",
    "# Afficher un aperçu des colonnes ajoutées\n",
    "print(\"\\nColonnes ajoutées:\")\n",
    "new_columns = [col for col in gdf_epci_metropole_enrichi.columns if col not in gdf_epci_metropole.columns]\n",
    "print(f\"Nombre de nouvelles colonnes: {len(new_columns)}\")\n",
    "print(new_columns[:10])  # Afficher les 10 premières nouvelles colonnes\n",
    "\n",
    "print(\"\\nAperçu du GeoDataFrame enrichi:\")\n",
    "print(gdf_epci_metropole_enrichi.head())\n",
    "\n",
    "# Le GeoDataFrame enrichi est maintenant prêt à être utilisé\n",
    "# Il contient toutes les statistiques demandées par EPCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a29b1ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
